{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf sdk_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-1.11.0%2Bcpu-cp39-cp39-linux_x86_64.whl (169.2 MB)\n",
      "     |████████████████████████████████| 169.2 MB 19 kB/s              \n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.12.0%2Bcpu-cp39-cp39-linux_x86_64.whl (14.7 MB)\n",
      "     |████████████████████████████████| 14.7 MB 43.5 MB/s            \n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-0.11.0%2Bcpu-cp39-cp39-linux_x86_64.whl (2.7 MB)\n",
      "     |████████████████████████████████| 2.7 MB 51.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch) (4.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.9/site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->torchvision) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->torchvision) (2.0.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->torchvision) (2021.10.8)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-1.11.0+cpu torchaudio-0.11.0+cpu torchvision-0.12.0+cpu\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Dataset only Download one of the data sets\n",
    "#!if [[ -d final_humor_sdk ]]; then rm -rf final_humor_sdk; fi\n",
    "#!curl -L -o original_data.zip https://www.dropbox.com/s/izk6khkrdwcncia/ted_humor_sdk_v1.zip\\?dl\\=1\n",
    "#!unzip original_data.zip\n",
    "#!rm original_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2 Raw Videos only Download one of the data sets\n",
    "!if [[ -d final_humor_sdk ]]; then rm -rf final_humor_sdk; fi\n",
    "!curl -L -o v2_raw_data.zip https://www.dropbox.com/s/lg7kjx0kul3ansq/urfunny2_videos.zip?dl=1\n",
    "!unzip v2_raw_data.zip\n",
    "!rm v2_raw_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2 Extracted Features only Download one of the data sets\n",
    "!if [[ -d final_humor_sdk ]]; then rm -rf final_humor_sdk; fi\n",
    "!curl -L -o https://www.dropbox.com/sh/9h0pcqmqoplx9p2/AAC8yYikSBVYCSFjm3afFHQva?dl=1\n",
    "!unzip v2_extracted_data.zip\n",
    "!rm v2_extracted_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "def load_pickle(pickle_file):\n",
    "    try:\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            pickle_data = pickle.load(f)\n",
    "    except UnicodeDecodeError as e:\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            pickle_data = pickle.load(f, encoding='latin1')\n",
    "    except Exception as e:\n",
    "        print('Unable to load data ', pickle_file, ':', e)\n",
    "        raise\n",
    "    return pickle_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "you can assign the maximum number number of sentences in context and what will be the maximum number of words of any sentence.\n",
    "\n",
    "It will do left padding . It will concatenate the word embedding + covarep features + openface features\n",
    "\n",
    "example:\n",
    "\n",
    "if max_sen_len = 20 then the punchline sentence dimension = 20 * 752. \n",
    "    where 752 = word embedding (300) + covarep (81) + openface(371)  \n",
    "\n",
    "if max_sen_len = 20 and max_context_len = 5 that means context can have maximum 5 sentences \n",
    "and each sentence will have maximum 20 words. The context dimension will be 5 * 20 * 752 \n",
    "\n",
    "We will do left padding with zeros to maintaing the same dimension.\n",
    "\n",
    "In our experiments we set max_sen_len = 20 & max_context_len = 5 \n",
    "'''\n",
    "\n",
    "\n",
    "class HumorDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, id_list,max_context_len=5,max_sen_len=20):\n",
    "        self.id_list = id_list\n",
    "        openface_file=\"sdk_features/openface_features_sdk.pkl\"\n",
    "        covarep_file=\"sdk_features/covarep_features_sdk.pkl\"\n",
    "        language_file=\"sdk_features/language_sdk.pkl\"\n",
    "        word_embedding_list_file=\"sdk_features/word_embedding_list.pkl\"\n",
    "        humor_label_file=\"sdk_features/humor_label_sdk.pkl\"\n",
    "        \n",
    "        self.word_aligned_openface_sdk=load_pickle(openface_file)\n",
    "        self.word_aligned_covarep_sdk=load_pickle(covarep_file)\n",
    "        self.language_sdk=load_pickle(language_file)\n",
    "        self.word_embedding_list_sdk=load_pickle(word_embedding_list_file)\n",
    "        self.humor_label_sdk = load_pickle(humor_label_file)\n",
    "        self.of_d=371\n",
    "        self.cvp_d=81\n",
    "        self.glove_d=300\n",
    "        self.total_dim=self.glove_d+self.of_d+self.cvp_d\n",
    "        self.max_context_len=max_context_len\n",
    "        self.max_sen_len=max_sen_len\n",
    "    \n",
    "    #left padding with zero  vector upto maximum number of words in a sentence * glove embedding dimension \n",
    "    def paded_word_idx(self,seq,max_sen_len=20,left_pad=1):\n",
    "        seq=seq[0:max_sen_len]\n",
    "        pad_w=np.concatenate((np.zeros(max_sen_len-len(seq)),seq),axis=0)\n",
    "        pad_w=np.array([self.word_embedding_list_sdk[int(w_id)] for  w_id in pad_w])\n",
    "        return pad_w\n",
    "    \n",
    "    #left padding with zero  vector upto maximum number of words in a sentence * covarep dimension \n",
    "    def padded_covarep_features(self,seq,max_sen_len=20,left_pad=1):\n",
    "        seq=seq[0:max_sen_len]\n",
    "        return np.concatenate((np.zeros((max_sen_len-len(seq),self.cvp_d)),seq),axis=0)\n",
    "    \n",
    "    #left padding with zero  vector upto maximum number of words in a sentence * openface dimension \n",
    "    def padded_openface_features(self,seq,max_sen_len=20,left_pad=1):\n",
    "        seq=seq[0:max_sen_len]\n",
    "        return np.concatenate((np.zeros(((max_sen_len-len(seq)),self.of_d)),seq),axis=0)\n",
    "    \n",
    "    #left padding with zero vectors upto maximum number of sentences in context * maximum num of words in a sentence * 456\n",
    "    def padded_context_features(self,context_w,context_of,context_cvp,max_context_len=5,max_sen_len=20):\n",
    "        context_w=context_w[-max_context_len:]\n",
    "        context_of=context_of[-max_context_len:]\n",
    "        context_cvp=context_cvp[-max_context_len:]\n",
    "\n",
    "        padded_context=[]\n",
    "        for i in range(len(context_w)):\n",
    "            p_seq_w=self.paded_word_idx(context_w[i],max_sen_len)\n",
    "            p_seq_cvp=self.padded_covarep_features(context_cvp[i],max_sen_len)\n",
    "            p_seq_of=self. padded_openface_features(context_of[i],max_sen_len)\n",
    "            padded_context.append(np.concatenate((p_seq_w,p_seq_cvp,p_seq_of),axis=1))\n",
    "\n",
    "        pad_c_len=max_context_len-len(padded_context)\n",
    "        padded_context=np.array(padded_context)\n",
    "        \n",
    "        #if there is no context\n",
    "        if not padded_context.any():\n",
    "            return np.zeros((max_context_len,max_sen_len,self.total_dim))\n",
    "        \n",
    "        return np.concatenate((np.zeros((pad_c_len,max_sen_len,self.total_dim)),padded_context),axis=0)\n",
    "    \n",
    "    def padded_punchline_features(self,punchline_w,punchline_of,punchline_cvp,max_sen_len=20,left_pad=1):\n",
    "        \n",
    "        p_seq_w=self.paded_word_idx(punchline_w,max_sen_len)\n",
    "        p_seq_cvp=self.padded_covarep_features(punchline_cvp,max_sen_len)\n",
    "        p_seq_of=self.padded_openface_features(punchline_of,max_sen_len)\n",
    "        return np.concatenate((p_seq_w,p_seq_cvp,p_seq_of),axis=1)\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.id_list)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        hid=self.id_list[index]\n",
    "        punchline_w=np.array(self.language_sdk[hid]['punchline_embedding_indexes'])\n",
    "        punchline_of=np.array(self.word_aligned_openface_sdk[hid]['punchline_features'])\n",
    "        punchline_cvp=np.array(self.word_aligned_covarep_sdk[hid]['punchline_features'])\n",
    "        \n",
    "        context_w=np.array(self.language_sdk[hid]['context_embedding_indexes'])\n",
    "        context_of=np.array(self.word_aligned_openface_sdk[hid]['context_features'])\n",
    "        context_cvp=np.array(self.word_aligned_covarep_sdk[hid]['context_features'])\n",
    "        \n",
    "        #punchline feature\n",
    "        x_p=torch.LongTensor(self.padded_punchline_features(punchline_w,punchline_of,punchline_cvp,self.max_sen_len))\n",
    "        #context feature\n",
    "        x_c=torch.LongTensor(self.padded_context_features(context_w,context_of,context_cvp,self.max_context_len,self.max_sen_len))\n",
    "        \n",
    "        y=torch.FloatTensor([self.humor_label_sdk[hid]])\n",
    "                \n",
    "        return x_p,x_c,y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folds_file=\"sdk_features/data_folds.pkl\"\n",
    "data_folds=load_pickle(data_folds_file)\n",
    "train=data_folds['train']\n",
    "dev=data_folds['dev']\n",
    "test=data_folds['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9588"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)+len(dev)+len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = HumorDataset(train)\n",
    "dev_set = HumorDataset(dev)\n",
    "test_set = HumorDataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=10\n",
    "train_dataloader = DataLoader(train_set, batch_size=batch, shuffle=True)\n",
    "dev_dataloader = DataLoader(dev_set, batch_size=batch, shuffle=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_82/2332142093.py:99: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  context_w=np.array(self.language_sdk[hid]['context_embedding_indexes'])\n",
      "/tmp/ipykernel_82/2332142093.py:100: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  context_of=np.array(self.word_aligned_openface_sdk[hid]['context_features'])\n",
      "/tmp/ipykernel_82/2332142093.py:101: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  context_cvp=np.array(self.word_aligned_covarep_sdk[hid]['context_features'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********\n",
      "punchline shape:  torch.Size([10, 20, 752])\n",
      "context shape:  torch.Size([10, 5, 20, 752])\n",
      "humor labels:  tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "*********\n",
      "punchline shape:  torch.Size([10, 20, 752])\n",
      "context shape:  torch.Size([10, 5, 20, 752])\n",
      "humor labels:  tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]])\n",
      "*********\n",
      "punchline shape:  torch.Size([10, 20, 752])\n",
      "context shape:  torch.Size([10, 5, 20, 752])\n",
      "humor labels:  tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "*********\n",
      "punchline shape:  torch.Size([10, 20, 752])\n",
      "context shape:  torch.Size([10, 5, 20, 752])\n",
      "humor labels:  tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "*********\n",
      "punchline shape:  torch.Size([10, 20, 752])\n",
      "context shape:  torch.Size([10, 5, 20, 752])\n",
      "humor labels:  tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "*********\n",
      "punchline shape:  torch.Size([10, 20, 752])\n",
      "context shape:  torch.Size([10, 5, 20, 752])\n",
      "humor labels:  tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "x_p.shape=batch_size*maximum number of words in sentence * 752\n",
    "x_c.shape = batch_size * maximum context length in #sentences * maximum sentence length in #words * 752\n",
    "here 752 = word embedding (300) + covarep (81) + openface(371)  \n",
    "'''\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "for  batch_idx, batch in enumerate(train_dataloader, 0): \n",
    "    x_p,x_c,y=map(lambda x: x.to(device), batch)\n",
    "    print(\"*********\")\n",
    "    print(\"punchline shape: \",x_p.shape)\n",
    "    print(\"context shape: \",x_c.shape)\n",
    "    print(\"humor labels: \",y)\n",
    "    if batch_idx==5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
